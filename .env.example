# ============================================
# Bolt.DIY Enhanced - Environment Variables
# ============================================
# Enhanced by itskiranbabu | Powered by KeyRun AI
#
# Copy this file to .env.local and fill in your API keys
# cp .env.example .env.local
#
# IMPORTANT: Never commit .env.local to Git!
# ============================================

# ============================================
# REQUIRED: At least ONE LLM provider
# ============================================

# OpenAI (Recommended)
# Get your key: https://platform.openai.com/api-keys
# Models: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
OPENAI_API_KEY=

# Anthropic (Claude)
# Get your key: https://console.anthropic.com/
# Models: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
ANTHROPIC_API_KEY=

# Google (Gemini)
# Get your key: https://makersuite.google.com/app/apikey
# Models: Gemini 1.5 Pro, Gemini 1.5 Flash
GOOGLE_GENERATIVE_AI_API_KEY=

# ============================================
# OPTIONAL: Additional LLM Providers
# ============================================

# Groq (Fast Inference)
# Get your key: https://console.groq.com/
# Models: Llama 3, Mixtral, Gemma
GROQ_API_KEY=

# OpenRouter (100+ Models)
# Get your key: https://openrouter.ai/keys
# Access to multiple providers through one API
OPENROUTER_API_KEY=

# Mistral AI
# Get your key: https://console.mistral.ai/
# Models: Mistral Large, Mistral Medium, Mistral Small
MISTRAL_API_KEY=

# Cohere
# Get your key: https://dashboard.cohere.com/api-keys
# Models: Command, Command Light
COHERE_API_KEY=

# DeepSeek
# Get your key: https://platform.deepseek.com/
# Models: DeepSeek Coder, DeepSeek Chat
DEEPSEEK_API_KEY=

# Together AI
# Get your key: https://api.together.xyz/settings/api-keys
# Models: Various open-source models
TOGETHER_API_KEY=

# Perplexity
# Get your key: https://www.perplexity.ai/settings/api
# Models: Perplexity models
PERPLEXITY_API_KEY=

# HuggingFace
# Get your key: https://huggingface.co/settings/tokens
# Access to HuggingFace models
HUGGINGFACE_API_KEY=

# ============================================
# LOCAL LLMs (No API key needed)
# ============================================

# Ollama (Local LLMs)
# Install: curl -fsSL https://ollama.com/install.sh | sh
# Start: ollama serve
# Pull model: ollama pull llama3
OLLAMA_API_BASE_URL=http://localhost:11434

# LM Studio (Local LLMs)
# Download: https://lmstudio.ai/
# Start local server and configure URL
LMSTUDIO_API_BASE_URL=http://localhost:1234

# ============================================
# CUSTOM OpenAI-Compatible Endpoints
# ============================================

# Any OpenAI-compatible API
OPENAI_LIKE_API_BASE_URL=
OPENAI_LIKE_API_KEY=

# ============================================
# APPLICATION SETTINGS
# ============================================

# Log Level (debug, info, warn, error)
VITE_LOG_LEVEL=info

# Max Response Segments
VITE_MAX_RESPONSE_SEGMENTS=10

# Enable Debug Mode
VITE_DEBUG=false

# ============================================
# DEPLOYMENT SETTINGS (Optional)
# ============================================

# Vercel
# These are automatically set by Vercel
# VERCEL=1
# VERCEL_ENV=production
# VERCEL_URL=your-app.vercel.app

# Netlify
# These are automatically set by Netlify
# NETLIFY=true
# CONTEXT=production
# URL=https://your-app.netlify.app

# Cloudflare Pages
# These are automatically set by Cloudflare
# CF_PAGES=1
# CF_PAGES_BRANCH=main
# CF_PAGES_URL=https://your-app.pages.dev

# ============================================
# ANALYTICS (Optional)
# ============================================

# Google Analytics
GA_TRACKING_ID=

# Vercel Analytics (automatically enabled on Vercel)
# No configuration needed

# ============================================
# SECURITY (Optional)
# ============================================

# Session Secret (for authentication)
SESSION_SECRET=

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:5173,https://yourdomain.com

# ============================================
# FEATURE FLAGS (Optional)
# ============================================

# Enable/Disable Features
VITE_ENABLE_GIT=true
VITE_ENABLE_TERMINAL=true
VITE_ENABLE_FILE_UPLOAD=true
VITE_ENABLE_EXPORT=true
VITE_ENABLE_COLLABORATION=false

# ============================================
# RATE LIMITING (Optional)
# ============================================

# Requests per minute
RATE_LIMIT_RPM=60

# Requests per hour
RATE_LIMIT_RPH=1000

# ============================================
# NOTES
# ============================================
#
# 1. At least ONE LLM provider API key is required
# 2. Local LLMs (Ollama, LM Studio) don't need API keys
# 3. Never commit .env.local to version control
# 4. Restart dev server after changing environment variables
# 5. For production, set these in your hosting platform
#
# ============================================
# GETTING API KEYS
# ============================================
#
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/
# Google: https://makersuite.google.com/app/apikey
# Groq: https://console.groq.com/
# OpenRouter: https://openrouter.ai/keys
#
# ============================================
# SUPPORT
# ============================================
#
# Documentation: https://github.com/itskiranbabu/bolt-diy-enhanced
# Issues: https://github.com/itskiranbabu/bolt-diy-enhanced/issues
# Community: https://whatsapp.com/channel/0029VbCCj7FGJP8EeBLXzD1C
# Email: itskeyrun.ai@gmail.com
#
# ============================================
